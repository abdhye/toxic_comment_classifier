# Toxic Comment Classifier
Created a toxic comment classifier by training data on ML algorithms.

An extract from the code:
![tccPy(1)](https://github.com/abdhye/toxic_comment_classifier/assets/56081405/abf4dbaa-09ef-44f1-8ba7-41d919d464f3)

![tccPy(3)](https://github.com/abdhye/toxic_comment_classifier/assets/56081405/fd15094e-fd82-4773-a5e8-54792d0d17e3)

The plot displays the F1 scores of machine learning models using TF-IDF.

1. Clone the repo to your local directory 
2. Create a new environment through Anaconda Prompt
3. Enter 'conda env create -f toxic_test.yml'
4. Enter 'python -m ipykernel install --user --name toxic --display-name toxic
5. Enter 'conda activate toxic' (you can deactivate the env later)

### running the flask app: 
1. Open Anaconda Prompt
2. Enter 'pip install flask'
3. Change directory to 'Flask app for toxic comments'
4. Enter 'python toxic_app.py' to run the Python file
5. Copy the IP address where the Flask is running at (eg. http://127.0.0.1:5000/) into your browser
6. You should see the app in action

